from ultralytics import YOLO
import cv2
import easyocr
import numpy as np

# ================== CONFIG ==================
MODEL_PATH = "best.pt"          # ƒë∆∞·ªùng d·∫´n t·ªõi model YOLO bi·ªÉn s·ªë
IMAGE_PATH = "test_BienSo.jpg"  # ƒë∆∞·ªùng d·∫´n t·ªõi ·∫£nh mu·ªën nh·∫≠n di·ªán
OCR_LANGS = ['en']  # bi·ªÉn s·ªë ch·ªß y·∫øu l√† s·ªë + ch·ªØ c√°i, 'en' l√† ƒë·ªß
# ===========================================


def load_image(path):
    img = cv2.imread(path)
    if img is None:
        print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh. Ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n: {path}")
        exit(1)
    return img


def init_yolo(model_path):
    try:
        model = YOLO(model_path)
        return model
    except Exception as e:
        print("‚ùå L·ªói khi load model YOLO, ki·ªÉm tra l·∫°i MODEL_PATH trong code.")
        print("Chi ti·∫øt l·ªói:", e)
        exit(1)


def init_ocr(langs):
    # gpu=False ƒë·ªÉ ch·∫Øc ch·∫Øn ch·∫°y ƒë∆∞·ª£c tr√™n Mac kh√¥ng c√≥ GPU CUDA
    reader = easyocr.Reader(langs, gpu=False)
    return reader


def preprocess_plate(plate_img):
    """Ti·ªÅn x·ª≠ l√Ω bi·ªÉn s·ªë tr∆∞·ªõc khi OCR cho n√©t h∆°n"""
    gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)

    # ph√≥ng to cho d·ªÖ ƒë·ªçc
    scale = 2.0
    gray = cv2.resize(
        gray, None,
        fx=scale,
        fy=scale,
        interpolation=cv2.INTER_LINEAR
    )

    # l√†m m·ªãn nh·∫π
    gray = cv2.GaussianBlur(gray, (3, 3), 0)

    # threshold (tu·ª≥ ·∫£nh, c√≥ th·ªÉ b·∫≠t/t·∫Øt ƒë·ªÉ th·ª≠)
    _, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    return th


def detect_and_ocr_plate():
    # 1. Load model + OCR
    model = init_yolo(MODEL_PATH)
    reader = init_ocr(OCR_LANGS)

    # 2. ƒê·ªçc ·∫£nh
    img = load_image(IMAGE_PATH)
    img_draw = img.copy()

    # 3. Ch·∫°y YOLO detect bi·ªÉn s·ªë
    results = model(img)[0]  # l·∫•y k·∫øt qu·∫£ cho ·∫£nh ƒë·∫ßu ti√™n

    if results.boxes is None or len(results.boxes) == 0:
        print("‚ö† Kh√¥ng t√¨m th·∫•y bi·ªÉn s·ªë n√†o trong ·∫£nh.")
        cv2.imshow("Result", img)
        cv2.waitKey(0)
        return

    print(f"üîé T√¨m th·∫•y {len(results.boxes)} bi·ªÉn s·ªë.")

    # 4. L·∫∑p qua t·ª´ng bounding box bi·ªÉn s·ªë
    for i, box in enumerate(results.boxes):
        # box.xyxy: [x1, y1, x2, y2]
        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)

        # Gi·ªõi h·∫°n trong size ·∫£nh cho an to√†n
        h, w = img.shape[:2]
        x1 = max(0, min(x1, w - 1))
        x2 = max(0, min(x2, w - 1))
        y1 = max(0, min(y1, h - 1))
        y2 = max(0, min(y2, h - 1))

        plate_img = img[y1:y2, x1:x2]

        if plate_img.size == 0:
            print(f"‚ö† Bi·ªÉn s·ªë {i} b·ªã crop l·ªói (k√≠ch th∆∞·ªõc 0). B·ªè qua.")
            continue

        # 5. Ti·ªÅn x·ª≠ l√Ω ·∫£nh bi·ªÉn s·ªë
        plate_proc = preprocess_plate(plate_img)

        # 6. OCR
        ocr_result = reader.readtext(plate_proc, detail=0, paragraph=True)
        text = " ".join(ocr_result).strip()

        print(f"üìå Bi·ªÉn s·ªë {i}: {text}")

        # 7. V·∫Ω bounding box + text l√™n ·∫£nh g·ªëc
        cv2.rectangle(img_draw, (x1, y1), (x2, y2), (0, 255, 0), 2)

        # ƒë·∫∑t text ngay tr√™n bbox
        cv2.putText(
            img_draw,
            text if text != "" else "N/A",
            (x1, max(y1 - 10, 0)),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.8,
            (0, 255, 0),
            2,
            cv2.LINE_AA
        )

        # 8. Hi·ªÉn th·ªã ri√™ng t·ª´ng bi·ªÉn s·ªë (t√πy, c√≥ th·ªÉ t·∫Øt)
        cv2.imshow(f"Plate {i}", plate_proc)

    # 9. Hi·ªÉn th·ªã ·∫£nh final
    cv2.imshow("Plate detection + OCR", img_draw)
    cv2.waitKey(0)
    cv2.destroyAllWindows()


if __name__ == "__main__":
    detect_and_ocr_plate()